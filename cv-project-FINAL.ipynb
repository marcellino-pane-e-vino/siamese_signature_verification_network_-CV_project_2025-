{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Authors: Luca Barbati (5082540), Roberto Lazzarini (4937188)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:30:20.338227Z",
     "iopub.status.busy": "2025-07-06T17:30:20.337617Z",
     "iopub.status.idle": "2025-07-06T17:30:20.343529Z",
     "shell.execute_reply": "2025-07-06T17:30:20.342888Z",
     "shell.execute_reply.started": "2025-07-06T17:30:20.338201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from enum import Enum\n",
    "import cv2\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Class          | Depends On                        |\n",
    "|----------------|-----------------------------------|\n",
    "| DatasetManager | cfg                               |\n",
    "| SiameseModel   | cfg                               |\n",
    "| Visualizer     | cfg, DatasetManager                              |\n",
    "| Controller     | cfg, DatasetManager, SiameseModel, Visualizer |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Config and enums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Config` class serves the purpose to store any global setting that needs to be accessed during the whole duration of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:30:20.346032Z",
     "iopub.status.busy": "2025-07-06T17:30:20.345208Z",
     "iopub.status.idle": "2025-07-06T17:30:20.372442Z",
     "shell.execute_reply": "2025-07-06T17:30:20.371804Z",
     "shell.execute_reply.started": "2025-07-06T17:30:20.346006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ModelType(Enum):\n",
    "    DISTANCE_BASED = \"distance_based\"\n",
    "    BINARY_CLASSIFICATION = \"binary_classification\"\n",
    "\n",
    "class DistanceMetric(Enum):\n",
    "    EUCLIDEAN = \"euclidean\"\n",
    "    COSINE = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:30:20.373690Z",
     "iopub.status.busy": "2025-07-06T17:30:20.373387Z",
     "iopub.status.idle": "2025-07-06T17:30:20.393893Z",
     "shell.execute_reply": "2025-07-06T17:30:20.393236Z",
     "shell.execute_reply.started": "2025-07-06T17:30:20.373666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, model_type, N_SHOTS=5, FORGERIES_ALPHA=0.5, ENVIRONMENT=\"kaggle\", GIANT_EXTRA_SET=\"True\"):\n",
    "        # dealing with N_SHOT logic  \n",
    "        self.MAX_SHOTS_PER_AUTHOR = 24\n",
    "        self.MAX_SHOTS_PER_TRAIN = int(self.MAX_SHOTS_PER_AUTHOR/2) # leaving half of the possible dataset for the extra validation set     \n",
    "        if int(N_SHOTS) > self.MAX_SHOTS_PER_TRAIN:\n",
    "            raise ValueError(f\"N_SHOTS cannot be greater than 24 (got {N_SHOTS})\")\n",
    "        self.N_SHOTS = int(N_SHOTS)\n",
    "        \n",
    "        # setting forgeries alpha\n",
    "        self.FORGERIES_ALPHA = float(FORGERIES_ALPHA)\n",
    "        \n",
    "        # Setup directories\n",
    "        self.ORG_DIR, self.FORG_DIR, self.OUTPUT_DIR = self._set_environment(ENVIRONMENT)\n",
    "        os.makedirs(self.OUTPUT_DIR, exist_ok=True)\n",
    "        \n",
    "        # Fixed parameters\n",
    "        self.EPOCHS = 50\n",
    "        self.TRAIN_RATIO = 0.7\n",
    "        self.VAL_RATIO = 0.3\n",
    "        self.IMG_SIZE = (155, 220)\n",
    "        self.BATCH_SIZE = 8\n",
    "        self.GIANT_EXTRA_SET = GIANT_EXTRA_SET # if True, the extra validation set will be composed of every positive or negative_forgery element not used in other datasets, if False, it will be proportional to the test_set size \n",
    "        \n",
    "        # Reproducibility\n",
    "        self.SEED = 42\n",
    "        tf.keras.utils.set_random_seed(self.SEED)\n",
    "        \n",
    "        # Model type + metric\n",
    "        self.MODEL_TYPE, self.DISTANCE_METRIC, self.MODEL_TYPE_STRING = self._choose_model_type(model_type)\n",
    "\n",
    "    # Sets the correct directories to work either locally or on the Kaggle online environment\n",
    "    def _set_environment(self, environment):\n",
    "        dataset_name = \"cedardataset\"\n",
    "        if environment == \"kaggle\":\n",
    "            root = f\"/kaggle/input/{dataset_name}/signatures\"\n",
    "            output_dir = \"/kaggle/working/output\"\n",
    "        elif environment == \"local\":\n",
    "            root = \"./signatures\"\n",
    "            output_dir = \"./output\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ENVIRONMENT: {environment}\")\n",
    "        org_dir = f\"{root}/full_org\"\n",
    "        forg_dir = f\"{root}/full_forg\"\n",
    "        self._am_i_in_the_right_environment(org_dir, forg_dir)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        return org_dir, forg_dir, output_dir\n",
    "\n",
    "    # Chooses the model type and distance metric based on the provided model_type string\n",
    "    def _choose_model_type(self, model_type):\n",
    "        if model_type == \"distance_euclidean\":\n",
    "            return ModelType.DISTANCE_BASED, DistanceMetric.EUCLIDEAN, model_type\n",
    "        elif model_type == \"distance_cosine\":\n",
    "            return ModelType.DISTANCE_BASED, DistanceMetric.COSINE, model_type\n",
    "        elif model_type == \"binary_classification\":\n",
    "            return ModelType.BINARY_CLASSIFICATION, None, model_type\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "\n",
    "    # raises an error if the directories are set up incorrectly\n",
    "    @staticmethod\n",
    "    def _am_i_in_the_right_environment(org_dir, forg_dir):\n",
    "        for d in [org_dir, forg_dir]:\n",
    "            if not os.path.exists(d):\n",
    "                raise RuntimeError(\"[ERROR] Wrong environment. Try switching it the other way around.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DatasetManager` class is responsible of:\n",
    "- retrieving the data samples from the dataset\n",
    "- building train, validation, test and extra sets on the basis of the chosen parameters\n",
    "- transforming the raw elements of each set into their correspondent pre-processed counterparts, on the basis of the pre-processing parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:30:20.442370Z",
     "iopub.status.busy": "2025-07-06T17:30:20.441787Z",
     "iopub.status.idle": "2025-07-06T17:30:20.472219Z",
     "shell.execute_reply": "2025-07-06T17:30:20.471578Z",
     "shell.execute_reply.started": "2025-07-06T17:30:20.442348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    # regex patterns to extract author IDs and forgeries\n",
    "    AUTHOR_RE = re.compile(r\"original_(\\d+)_\\d+\\.png\")\n",
    "    FORGERY_RE_TEMPLATE = r\"forgeries_{}_\\d+\\.png\"\n",
    "\n",
    "    def __init__(self, config, blur_kernel_size=3, binarize=True, center=True):\n",
    "        self.cfg = config\n",
    "        \n",
    "        # setting pre-processing parameters\n",
    "        self.blur_kernel_size = blur_kernel_size\n",
    "        self.binarize = binarize\n",
    "        self.center = center\n",
    "        \n",
    "        # initialize directories and file lists\n",
    "        self.file_list = self._load_file_list()\n",
    "        self.author_ids = self._extract_all_author_ids()\n",
    "        self.forg_dir_files = os.listdir(self.cfg.FORG_DIR)\n",
    "\n",
    "        # initialize empty DataFrames for positive and negative pairs\n",
    "        empty_cols = [\"image1\", \"image2\", \"label\"]\n",
    "        self.pos_df = pd.DataFrame(columns=empty_cols)\n",
    "        self.neg_df = pd.DataFrame(columns=empty_cols)\n",
    "        \n",
    "        # initialize empty DataFrames for train, validation, test, and extra sets\n",
    "        self.train_df = pd.DataFrame(columns=empty_cols)\n",
    "        self.val_df = pd.DataFrame(columns=empty_cols)\n",
    "        self.test_df = pd.DataFrame(columns=empty_cols)\n",
    "        self.extra_df = pd.DataFrame(columns=empty_cols)\n",
    "\n",
    "    def prepare_datasets(self, verbose=True):\n",
    "        positives_path_to_exclude = self._generate_positive_pairs()\n",
    "        forgeries_path_to_exclude = self._generate_negative_pairs()\n",
    "\n",
    "        self._split_data()\n",
    "        train = self._make_numpy_dataset(self.train_df)\n",
    "        val = self._make_numpy_dataset(self.val_df)\n",
    "        test = self._make_numpy_dataset(self.test_df)\n",
    "        len_test = len(self.test_df)\n",
    "\n",
    "        extra_set = self._prepare_extra_set(positives_path_to_exclude, forgeries_path_to_exclude, len_test)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"[INFO] Dataset prepared with {train[0][0].shape[0]} training samples, {val[0][0].shape[0]} validation samples, and {test[0][0].shape[0]} test samples.\")\n",
    "            if extra_set:\n",
    "                print(f\"[INFO] Extra set has size {extra_set[0][0].shape[0]}\")\n",
    "            else:\n",
    "                print(f\"[INFO] Extra set has size 0\")\n",
    "\n",
    "        return train, val, test, extra_set\n",
    "\n",
    "    def _prepare_extra_set(self, positives_path_to_exclude, forgeries_path_to_exclude, len_test):\n",
    "        all_forgeries_path = self._generate_negatives_forg(self.cfg.MAX_SHOTS_PER_AUTHOR, self.forg_dir_files)\n",
    "        forgeries_path_to_use = [x for x in all_forgeries_path if x not in forgeries_path_to_exclude]\n",
    "\n",
    "        all_positives_path = self._generate_all_positive_pairs()\n",
    "        positives_path_to_use = [x for x in all_positives_path if x not in positives_path_to_exclude]\n",
    "\n",
    "        if self.cfg.GIANT_EXTRA_SET:\n",
    "            len_test = min(len(positives_path_to_use), len(forgeries_path_to_use))\n",
    "        \n",
    "        extra_set = []\n",
    "        if len(forgeries_path_to_use) > 0 and len(positives_path_to_use) > 0:\n",
    "            extra_set = forgeries_path_to_use[:len_test // 2] + positives_path_to_use[:len_test // 2]\n",
    "            extra_set = pd.DataFrame(extra_set, columns=[\"image1\", \"image2\", \"label\"])\n",
    "            self.extra_df = extra_set.copy()\n",
    "            extra_set = self._make_numpy_dataset(extra_set)\n",
    "        return extra_set\n",
    "\n",
    "    def load_and_preprocess(self, path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"File not found: {path}\")\n",
    "        img = cv2.resize(img, (self.cfg.IMG_SIZE[1], self.cfg.IMG_SIZE[0]))\n",
    "        img = cv2.GaussianBlur(img, (self.blur_kernel_size, self.blur_kernel_size), 1.0)\n",
    "        if self.binarize:\n",
    "            _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        if self.center:\n",
    "            img = self._center_signature(img)\n",
    "        return img\n",
    "\n",
    "    def _load_file_list(self):\n",
    "        return [\n",
    "            f for f in os.listdir(self.cfg.ORG_DIR) if f.lower().endswith('.png')\n",
    "        ]\n",
    "\n",
    "    def _extract_all_author_ids(self):\n",
    "        return sorted({\n",
    "            self._extract_author_id(f)\n",
    "            for f in self.file_list\n",
    "            if self._extract_author_id(f) is not None\n",
    "        })\n",
    "\n",
    "    def _extract_author_id(self, filename):\n",
    "        match = self.AUTHOR_RE.match(filename)\n",
    "        return match.group(1) if match else None\n",
    "\n",
    "    def _generate_positive_pairs(self):\n",
    "        pos_pairs = []\n",
    "        n_pos = self.cfg.N_SHOTS\n",
    "        for aut in self.author_ids:\n",
    "            ref = os.path.join(self.cfg.ORG_DIR, f\"original_{aut}_1.png\")\n",
    "            for idx in range(2, n_pos + 2):\n",
    "                gen = os.path.join(self.cfg.ORG_DIR, f\"original_{aut}_{idx}.png\")\n",
    "                if os.path.exists(ref) and os.path.exists(gen):\n",
    "                    pos_pairs.append((ref, gen, 1))\n",
    "        self.pos_df = pd.DataFrame(pos_pairs, columns=[\"image1\", \"image2\", \"label\"])\n",
    "        return pos_pairs\n",
    "\n",
    "    def _generate_all_positive_pairs(self):\n",
    "        \"\"\"Generate all possible positive pairs for all authors, with no sampling.\"\"\"\n",
    "        pos_pairs = []\n",
    "        for aut in self.author_ids:\n",
    "            ref = os.path.join(self.cfg.ORG_DIR, f\"original_{aut}_1.png\")\n",
    "            for idx in range(1, self.cfg.MAX_SHOTS_PER_AUTHOR + 1):\n",
    "                gen = os.path.join(self.cfg.ORG_DIR, f\"original_{aut}_{idx}.png\")\n",
    "                if os.path.exists(ref) and os.path.exists(gen):\n",
    "                    pos_pairs.append((ref, gen, 1))\n",
    "        return pos_pairs\n",
    "\n",
    "    def _generate_negative_pairs(self):\n",
    "        n_shots = self.cfg.N_SHOTS\n",
    "        forgeries_alpha = self.cfg.FORGERIES_ALPHA\n",
    "\n",
    "        if forgeries_alpha == 0.5:\n",
    "            n_neg_cross = int(math.ceil(n_shots * 0.5))\n",
    "            n_neg_forg = int(math.ceil(n_shots * 0.5))\n",
    "        else:\n",
    "            n_neg_cross = int(math.floor(n_shots * (1 - forgeries_alpha)))\n",
    "            n_neg_forg = int(n_shots - n_neg_cross)\n",
    "        \n",
    "    \n",
    "        neg_pairs = []\n",
    "        neg_pairs += self._generate_negatives_auth(n_neg_cross)\n",
    "        forgeries_to_exclude = self._generate_negatives_forg(n_neg_forg, self.forg_dir_files)\n",
    "        neg_pairs += forgeries_to_exclude\n",
    "\n",
    "        self.neg_df = pd.DataFrame(neg_pairs, columns=[\"image1\", \"image2\", \"label\"])\n",
    "        print(f\"N_POS: {n_shots}, N_NEG_FORG: {n_neg_forg}, N_NEG_CROSS: {n_neg_cross}\")\n",
    "        return forgeries_to_exclude\n",
    "\n",
    "    def _generate_negatives_auth(self, n_neg_cross):\n",
    "        neg_pairs = []\n",
    "        for aut in self.author_ids:\n",
    "            ref = os.path.join(self.cfg.ORG_DIR, f\"original_{aut}_1.png\")\n",
    "            other_authors = [a for a in self.author_ids if a != aut]\n",
    "            sampled_others = random.sample(other_authors, min(n_neg_cross, len(other_authors))) if other_authors else []\n",
    "            for neg_aut in sampled_others:\n",
    "                neg_img = os.path.join(self.cfg.ORG_DIR, f\"original_{neg_aut}_2.png\")\n",
    "                if os.path.exists(neg_img):\n",
    "                    neg_pairs.append((ref, neg_img, 0))\n",
    "        return neg_pairs\n",
    "\n",
    "    def _generate_negatives_forg(self, n_neg_forg, forg_dir_files):\n",
    "        neg_pairs = []\n",
    "        for aut in self.author_ids:\n",
    "            ref = os.path.join(self.cfg.ORG_DIR, f\"original_{aut}_1.png\")\n",
    "            forgery_pat = re.compile(self.FORGERY_RE_TEMPLATE.format(aut))\n",
    "            forger_list = [f for f in forg_dir_files if forgery_pat.match(f)]\n",
    "            sampled_forgers = random.sample(forger_list, min(n_neg_forg, len(forger_list))) if forger_list else []\n",
    "            for forg_file in sampled_forgers:\n",
    "                forg_path = os.path.join(self.cfg.FORG_DIR, forg_file)\n",
    "                if os.path.exists(forg_path):\n",
    "                    neg_pairs.append((ref, forg_path, 0))\n",
    "        return neg_pairs\n",
    "\n",
    "    def _split_data(self):\n",
    "        df = pd.concat([self.pos_df, self.neg_df], ignore_index=True)\n",
    "        trainval_df, self.test_df = train_test_split(\n",
    "            df, train_size=self.cfg.TRAIN_RATIO, stratify=df[\"label\"], random_state=self.cfg.SEED\n",
    "        )\n",
    "        self.train_df, self.val_df = train_test_split(\n",
    "            trainval_df, test_size=self.cfg.VAL_RATIO, stratify=trainval_df[\"label\"], random_state=self.cfg.SEED\n",
    "        )\n",
    "\n",
    "    def _center_signature(self, img):\n",
    "        img_bin = (img.squeeze(-1) * 255).astype(np.uint8)\n",
    "        canvas_h, canvas_w = img_bin.shape\n",
    "        coords = cv2.findNonZero(255 - img_bin)\n",
    "        if coords is None:\n",
    "            canvas = np.ones((canvas_h, canvas_w), dtype=np.uint8) * 255\n",
    "        else:\n",
    "            x, y, w, h = cv2.boundingRect(coords)\n",
    "            signature_crop = img_bin[y:y + h, x:x + w]\n",
    "            scale = min(canvas_w / w, canvas_h / h, 1.0)\n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            signature_resized = cv2.resize(signature_crop, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            canvas = np.ones((canvas_h, canvas_w), dtype=np.uint8) * 255\n",
    "            start_x = (canvas_w - new_w) // 2\n",
    "            start_y = (canvas_h - new_h) // 2\n",
    "            canvas[start_y:start_y + new_h, start_x:start_x + new_w] = signature_resized\n",
    "        centered_img = (canvas.astype(np.float32) / 255.0)[..., np.newaxis]\n",
    "        return centered_img\n",
    "\n",
    "    def _preprocess_pair(self, p1, p2, label):\n",
    "        img1 = self.load_and_preprocess(p1)\n",
    "        img2 = self.load_and_preprocess(p2)\n",
    "        return (img1, img2), float(label)\n",
    "\n",
    "    def _make_numpy_dataset(self, df):\n",
    "        images1, images2, labels = [], [], []\n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                (img1, img2), label = self._preprocess_pair(row['image1'], row['image2'], row['label'])\n",
    "                images1.append(img1)\n",
    "                images2.append(img2)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Could not process pair {row['image1']} {row['image2']}: {e}\")\n",
    "        images1 = np.stack(images1)\n",
    "        images2 = np.stack(images2)\n",
    "        labels = np.array(labels)\n",
    "        return (images1, images2), labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SiameseModel` class is responsible of:\n",
    "- building the model, depending on: \n",
    "    - the chosen strategy (either distance-based or binary classification) \n",
    "    - in case of distance-based models, the distance metric (cosine or euclidean). \n",
    "- training the model\n",
    "- getting the predictions\n",
    "- evaluating the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:30:20.474191Z",
     "iopub.status.busy": "2025-07-06T17:30:20.473734Z",
     "iopub.status.idle": "2025-07-06T17:30:20.511152Z",
     "shell.execute_reply": "2025-07-06T17:30:20.510489Z",
     "shell.execute_reply.started": "2025-07-06T17:30:20.474163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SiameseModel:\n",
    "    def __init__(self, config):\n",
    "        # initializes the Siamese model with the provided configuration\n",
    "        self.cfg = config\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.best_threshold = None\n",
    "        \n",
    "        # sets up the model type and distance metric\n",
    "        self.strategy = self._pick_strategy()\n",
    "        \n",
    "        # sets up the callbacks for training\n",
    "        self.callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                save_best_only=True,\n",
    "                filepath=os.path.join(self.cfg.OUTPUT_DIR, \"best_siamese_model.keras\"),\n",
    "                verbose=0,\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                patience=10,\n",
    "                restore_best_weights=True,\n",
    "                verbose=0,\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\",\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-7,\n",
    "                verbose=0,\n",
    "            ),\n",
    "        ]\n",
    "    def _pick_strategy(self):\n",
    "        if self.cfg.MODEL_TYPE == ModelType.DISTANCE_BASED:\n",
    "            return DistanceBasedStrategy(self.cfg)\n",
    "        else:\n",
    "            return BinaryClassificationStrategy(self.cfg)\n",
    "\n",
    "    # builds the single branch that will compose the Siamese network\n",
    "    @staticmethod\n",
    "    def signet_cnn_simple(input_shape=(155, 220, 1)):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Conv2D(64, (3,3), padding='same')(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Conv2D(128, (3,3), padding='same')(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Conv2D(256, (3,3), padding='same')(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((4,4))(x)\n",
    "        x = layers.Conv2D(256, (1,1))(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(128)(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        x = layers.Dense(32)(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        return Model(inputs, x, name=\"SigNetCNN_Simple\")\n",
    "\n",
    "    # builds the Siamese model using the previously established single branch and strategy\n",
    "    def build(self):\n",
    "        input_shape = self.cfg.IMG_SIZE + (1,)\n",
    "        embedding_net = self.signet_cnn_simple(input_shape)\n",
    "        input_a = layers.Input(shape=input_shape)\n",
    "        input_b = layers.Input(shape=input_shape)\n",
    "        output = self.strategy.build_model(embedding_net, input_a, input_b)\n",
    "        self.model = models.Model([input_a, input_b], output)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "        metrics_config = self.strategy.get_model_metrics()\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=metrics_config['loss'],\n",
    "            metrics=metrics_config['metrics']\n",
    "        )\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val, epochs, callbacks=None):\n",
    "        self.history = self.model.fit(\n",
    "            x=[x_train[0], x_train[1]],\n",
    "            y=y_train,\n",
    "            validation_data=([x_val[0], x_val[1]], y_val),\n",
    "            epochs=epochs,\n",
    "            callbacks=self.callbacks,\n",
    "            verbose=1,\n",
    "            batch_size=self.cfg.BATCH_SIZE\n",
    "        )\n",
    "        return self.history\n",
    "\n",
    "    def predict(self, x1, x2):\n",
    "        return self.model.predict([x1, x2], verbose=0)\n",
    "\n",
    "    def get_predictions_and_labels(self, dataset):\n",
    "        (X1, X2), Y = dataset\n",
    "        preds = self.model.predict([X1, X2], verbose=0)\n",
    "        return preds.flatten(), Y.flatten()\n",
    "\n",
    "    def evaluate_predictions(self, predictions, labels):\n",
    "        results = self.strategy.evaluate_predictions(predictions, labels)\n",
    "        # update best_threshold attribute if present\n",
    "        if 'best_threshold' in results:\n",
    "            self.best_threshold = results['best_threshold']\n",
    "            #print(f\"I am updating the threshold to {self.best_threshold}.\")\n",
    "        else:\n",
    "            self.best_threshold = None\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceBasedStrategy:\n",
    "    def __init__(self, config):\n",
    "        self.cfg = config\n",
    "\n",
    "    def build_model(self, embedding_net, input_a, input_b):\n",
    "        feat_a = embedding_net(input_a)\n",
    "        feat_b = embedding_net(input_b)\n",
    "        if self.cfg.DISTANCE_METRIC == DistanceMetric.EUCLIDEAN:\n",
    "            distance_layer = layers.Lambda(self.euclidean_distance)([feat_a, feat_b])\n",
    "        else:\n",
    "            distance_layer = layers.Lambda(self.cosine_distance)([feat_a, feat_b])\n",
    "        return distance_layer\n",
    "\n",
    "    def get_model_metrics(self):\n",
    "        return {'loss': self.contrastive_loss_improved, 'metrics': [self.siamese_accuracy]}\n",
    "\n",
    "    @staticmethod\n",
    "    def euclidean_distance(vects):\n",
    "        x, y = vects\n",
    "        sum_sq = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "        return tf.sqrt(tf.maximum(sum_sq, tf.keras.backend.epsilon()))\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_distance(vects):\n",
    "        x, y = vects\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        y = tf.nn.l2_normalize(y, axis=1)\n",
    "        return 1 - tf.reduce_sum(x * y, axis=1, keepdims=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def contrastive_loss_improved(y_true, y_pred, margin=1.0):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        positive_loss = y_true * tf.square(y_pred)\n",
    "        negative_loss = (1 - y_true) * tf.square(tf.maximum(margin - y_pred, 0))\n",
    "        return tf.reduce_mean(positive_loss + negative_loss)\n",
    "\n",
    "    @staticmethod\n",
    "    def siamese_accuracy(y_true, y_pred, threshold=1.0):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        predictions = tf.cast(y_pred < threshold, tf.float32)\n",
    "        return tf.keras.metrics.binary_accuracy(y_true, predictions)\n",
    "\n",
    "    def evaluate_predictions(self, predictions, labels):\n",
    "        best_threshold, best_acc = self.find_best_threshold(predictions, labels)\n",
    "        test_predictions = (predictions < best_threshold).astype(int)\n",
    "        test_accuracy = (test_predictions == labels).mean()\n",
    "        try:\n",
    "            auc_score = roc_auc_score(labels, 1 - predictions)\n",
    "        except Exception:\n",
    "            auc_score = None\n",
    "        return {\n",
    "            'accuracy': test_accuracy,\n",
    "            'auc': auc_score,\n",
    "            'best_threshold': best_threshold,\n",
    "            'predictions': test_predictions\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def find_best_threshold(distances, labels):\n",
    "        thresholds = np.linspace(distances.min(), distances.max(), 100)\n",
    "        best_acc = 0\n",
    "        best_thresh = 0\n",
    "        for thresh in thresholds:\n",
    "            predictions = (distances < thresh).astype(int)\n",
    "            accuracy = (predictions == labels).mean()\n",
    "            if accuracy > best_acc:\n",
    "                best_acc = accuracy\n",
    "                best_thresh = thresh\n",
    "        return best_thresh, best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassificationStrategy:\n",
    "    def __init__(self, config):\n",
    "        self.cfg = config\n",
    "\n",
    "    def build_model(self, embedding_net, input_a, input_b):\n",
    "        feat_a = embedding_net(input_a)\n",
    "        feat_b = embedding_net(input_b)\n",
    "        concatenated_emb = layers.Concatenate(axis=1)([feat_a, feat_b])\n",
    "        x = layers.Dense(128, activation='relu')(concatenated_emb)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.Dense(1, activation='sigmoid')(x)\n",
    "        return x\n",
    "\n",
    "    def get_model_metrics(self):\n",
    "        return {'loss': 'binary_crossentropy', 'metrics': ['accuracy']}\n",
    "\n",
    "    def evaluate_predictions(self, predictions, labels):\n",
    "        test_predictions = (predictions >= 0.5).astype(int)\n",
    "        test_accuracy = (test_predictions == labels).mean()\n",
    "        try:\n",
    "            auc_score = roc_auc_score(labels, predictions)\n",
    "        except Exception:\n",
    "            auc_score = None\n",
    "        return {\n",
    "            'accuracy': test_accuracy,\n",
    "            'auc': auc_score,\n",
    "            'best_threshold': 0.5,\n",
    "            'predictions': test_predictions\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. View Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can easily deduce, the `Visualizer` class is responsible of visually showcasing the model's results by showing its predictions and plots of various metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:30:20.512141Z",
     "iopub.status.busy": "2025-07-06T17:30:20.511915Z",
     "iopub.status.idle": "2025-07-06T17:30:20.541344Z",
     "shell.execute_reply": "2025-07-06T17:30:20.540694Z",
     "shell.execute_reply.started": "2025-07-06T17:30:20.512124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self, config):\n",
    "        self.cfg = config\n",
    "        self.dm = None # not explicitly a class-inherited parameter, but will be set later when the DatasetManager is created\n",
    "\n",
    "    def plot_history(self, history):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        key_acc = [k for k in history.history if 'accuracy' in k]\n",
    "        for k in key_acc:\n",
    "            plt.plot(history.history[k], label=k)\n",
    "        plt.title('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_accuracy_vs_shots(self, shots_list, test_accs, forgery_accs):\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(shots_list, test_accs, '-o', label='Test accuracy')\n",
    "        plt.plot(shots_list, forgery_accs, '-s', label='Forgery accuracy')\n",
    "        plt.xlabel('N_SHOTS')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy vs. N_SHOTS')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_accuracy_vs_alpha(self, alpha_list, test_accs, forgery_accs):\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(alpha_list, test_accs, '-o', label='Test accuracy')\n",
    "        plt.plot(alpha_list, forgery_accs, '-s', label='Forgery accuracy')\n",
    "        plt.xlabel('FORGERIES_ALPHA')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy vs. FORGERIES_ALPHA')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def print_test_results_table(self, preds, labels, threshold):\n",
    "        pred_labels = (preds < threshold).astype(int)  # For distance-based; adjust if using classification\n",
    "        print(\"Prediction\\tLabel\\tCorrect\")\n",
    "        for i in range(len(labels)):\n",
    "            print(f\"{pred_labels[i]}\\t\\t{int(labels[i])}\\t{pred_labels[i]==labels[i]}\")\n",
    "\n",
    "    def plot_test_examples(self, model, test_df, evaluation_results, outpath, num_examples=4):\n",
    "        test_df_sample = test_df.sample(n=min(num_examples, len(test_df)), random_state=self.cfg.SEED)\n",
    "        fig, axes = plt.subplots(2, num_examples, figsize=(4*num_examples, 8))\n",
    "    \n",
    "        for i, (_, row) in enumerate(test_df_sample.iterrows()):\n",
    "            if not os.path.exists(row['image1']) or not os.path.exists(row['image2']):\n",
    "                print(f\"[WARN] Missing file: {row['image1']} or {row['image2']}. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            try:\n",
    "                img1_disp = self.dm.load_and_preprocess(row['image1']).squeeze()\n",
    "                img2_disp = self.dm.load_and_preprocess(row['image2']).squeeze()\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Error loading images: {e}. Skipping sample.\")\n",
    "                continue\n",
    "    \n",
    "            try:\n",
    "                img1_for_model = img1_disp[None, ..., None] if img1_disp.ndim == 2 else img1_disp[None, ...]\n",
    "                img2_for_model = img2_disp[None, ..., None] if img2_disp.ndim == 2 else img2_disp[None, ...]\n",
    "                pred_value = model.model.predict([img1_for_model, img2_for_model], verbose=0)[0][0]\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Error in model prediction: {e}. Skipping sample.\")\n",
    "                continue\n",
    "    \n",
    "            # Determine prediction\n",
    "            if self.cfg.MODEL_TYPE == ModelType.DISTANCE_BASED:\n",
    "                prediction = \"AUTHENTIC\" if pred_value < evaluation_results['best_threshold'] else \"DIFFERENT\"\n",
    "                pred_label = f'Dist: {pred_value:.2f}'\n",
    "            else:\n",
    "                prediction = \"AUTHENTIC\" if pred_value >= 0.5 else \"DIFFERENT\"\n",
    "                pred_label = f'Prob: {pred_value:.2f}'\n",
    "    \n",
    "            actual = \"AUTHENTIC\" if row['label'] == 1 else \"DIFFERENT\"\n",
    "            \n",
    "            # Show images with black borders\n",
    "            axes[0, i].imshow(img1_disp, cmap='gray')\n",
    "            axes[0, i].set_title('Reference')\n",
    "            axes[0, i].axis('off')\n",
    "            rect1 = patches.Rectangle((0, 0), img1_disp.shape[1]-1, img1_disp.shape[0]-1, \n",
    "                                      linewidth=2, edgecolor='black', facecolor='none')\n",
    "            axes[0, i].add_patch(rect1)\n",
    "            \n",
    "            axes[1, i].imshow(img2_disp, cmap='gray')\n",
    "            axes[1, i].set_title(f'Query\\n{pred_label}\\nPred: {prediction}\\nReal: {actual}')\n",
    "            axes[1, i].axis('off')\n",
    "            rect2 = patches.Rectangle((0, 0), img2_disp.shape[1]-1, img2_disp.shape[0]-1, \n",
    "                                      linewidth=2, edgecolor='black', facecolor='none')\n",
    "            axes[1, i].add_patch(rect2)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ExperimentController` class serves to organize and script three experiment pipelines:\n",
    "- Single experiment\n",
    "- performance_analysis_n_shots\n",
    "- performance_analysis_forgeries_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:30:20.543343Z",
     "iopub.status.busy": "2025-07-06T17:30:20.543063Z",
     "iopub.status.idle": "2025-07-06T17:30:20.569357Z",
     "shell.execute_reply": "2025-07-06T17:30:20.568727Z",
     "shell.execute_reply.started": "2025-07-06T17:30:20.543325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ExperimentController:\n",
    "    def __init__(self, config, model_cls, data_cls, visualizer):\n",
    "        self.cfg = config\n",
    "        self.ModelCls = model_cls\n",
    "        self.DataCls = data_cls\n",
    "        self.visualizer = visualizer\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_forgery_accuracy(model, extra):\n",
    "        preds_extra, labels_extra = model.get_predictions_and_labels(extra)\n",
    "        results_extra = model.evaluate_predictions(preds_extra, labels_extra)\n",
    "        return results_extra['accuracy']\n",
    "\n",
    "    @staticmethod\n",
    "    def perc_false_positives(preds, labels):\n",
    "        positive_mask = (labels == 1)\n",
    "        if positive_mask.sum() == 0:\n",
    "            return 0.0\n",
    "        false_positives = ((labels == 1) & (preds == 0)).sum()\n",
    "        return 100.0 * false_positives / positive_mask.sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def perc_false_negatives(preds, labels):\n",
    "        negative_mask = (labels == 0)\n",
    "        if negative_mask.sum() == 0:\n",
    "            return 0.0\n",
    "        false_negatives = ((labels == 0) & (preds == 1)).sum()\n",
    "        return 100.0 * false_negatives / negative_mask.sum()\n",
    "\n",
    "    def single_experiment(self, blur_kernel_size=3, binarize=True, center=True):\n",
    "        dm = self.DataCls(self.cfg, blur_kernel_size, binarize, center)\n",
    "        train, val, test, extra = dm.prepare_datasets()\n",
    "        model = self.ModelCls(self.cfg)\n",
    "        model.build()\n",
    "        history = model.train(train[0], train[1], val[0], val[1], self.cfg.EPOCHS)\n",
    "        self.visualizer.plot_history(history)\n",
    "\n",
    "        preds, labels = model.get_predictions_and_labels(test)\n",
    "        results = model.evaluate_predictions(preds, labels)\n",
    "        forgery_acc = self.compute_forgery_accuracy(model, extra)\n",
    "        preds_extra, labels_extra = model.get_predictions_and_labels(extra)\n",
    "        predictions_bin = model.strategy.evaluate_predictions(preds_extra, labels_extra)['predictions']\n",
    "        perc_fp = self.perc_false_positives(predictions_bin, labels_extra)\n",
    "        perc_fn = self.perc_false_negatives(predictions_bin, labels_extra)\n",
    "        \n",
    "        print(f\"\\nTest accuracy: {results['accuracy']:.3f} (AUC: {results['auc']:.3f})\")\n",
    "        print(f\"\\nForgery accuracy: {forgery_acc:.3f}\")\n",
    "        print(f\"Percentage False Positive: {perc_fp:.2f}%\")\n",
    "        print(f\"Percentage False Negative: {perc_fn:.2f}%\")\n",
    "\n",
    "        self.visualizer.dm = dm\n",
    "        self.visualizer.plot_test_examples(model=model,test_df=dm.test_df,evaluation_results=results,outpath=\"test_examples.png\",num_examples=4)\n",
    "        self.visualizer.plot_test_examples(model=model,test_df=dm.extra_df,evaluation_results=results,outpath=\"extra_examples.png\",num_examples=4)\n",
    "        # return results, forgery_acc\n",
    "\n",
    "    def performance_analysis_n_shots(self, shots_list, blur_kernel_size=3, binarize=True, center=True):\n",
    "        test_accs, forgery_accs = [], []\n",
    "        perc_fp_list, perc_fn_list = [], []\n",
    "        for n_shots in shots_list:\n",
    "            cfg = Config(self.cfg.MODEL_TYPE_STRING, N_SHOTS=n_shots, FORGERIES_ALPHA=self.cfg.FORGERIES_ALPHA)\n",
    "            dm = self.DataCls(cfg, blur_kernel_size, binarize, center)\n",
    "            train, val, test, extra = dm.prepare_datasets()\n",
    "            model = self.ModelCls(cfg)\n",
    "            model.build()\n",
    "            model.train(train[0], train[1], val[0], val[1], cfg.EPOCHS)\n",
    "            preds, labels = model.get_predictions_and_labels(test)\n",
    "            results = model.evaluate_predictions(preds, labels)\n",
    "            forgery_acc = self.compute_forgery_accuracy(model, extra)\n",
    "\n",
    "            preds_extra, labels_extra = model.get_predictions_and_labels(extra)\n",
    "            predictions_bin = model.strategy.evaluate_predictions(preds_extra, labels_extra)['predictions']\n",
    "            perc_fp = self.perc_false_positives(predictions_bin, labels_extra)\n",
    "            perc_fn = self.perc_false_negatives(predictions_bin, labels_extra)\n",
    "            perc_fp_list.append(perc_fp)\n",
    "            perc_fn_list.append(perc_fn)\n",
    "\n",
    "            test_accs.append(results['accuracy'])\n",
    "            forgery_accs.append(forgery_acc)\n",
    "            print(f\"[n_shots={n_shots}] Test Acc: {results['accuracy']:.3f}\\tForgery Acc: {forgery_acc:.3f}\\tFP%: {perc_fp:.2f}\\tFN%: {perc_fn:.2f}\")\n",
    "\n",
    "        # Plot accuracy\n",
    "        self.visualizer.plot_accuracy_vs_shots(shots_list, test_accs, forgery_accs)\n",
    "        # Plot FP/FN percentage\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(shots_list, perc_fp_list, '-o', label='False Positive (%)', color='#6A5ACD')  \n",
    "        plt.plot(shots_list, perc_fn_list, '-s', label='False Negative (%)', color='#228B22')  \n",
    "        plt.xlabel('N_SHOTS')\n",
    "        plt.ylabel('Error Percentage (%)')\n",
    "        plt.title('False Positive and False Negative (%) vs N_SHOTS')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def performance_analysis_forgeries_alpha(self, alpha_list, blur_kernel_size=3, binarize=True, center=True):\n",
    "        test_accs, forgery_accs = [], []\n",
    "        perc_fp_list, perc_fn_list = [], []\n",
    "        for alpha in alpha_list:\n",
    "            cfg = Config(self.cfg.MODEL_TYPE_STRING, N_SHOTS=self.cfg.N_SHOTS, FORGERIES_ALPHA=alpha)\n",
    "            dm = self.DataCls(cfg, blur_kernel_size, binarize, center)\n",
    "            train, val, test, extra = dm.prepare_datasets()\n",
    "            model = self.ModelCls(cfg)\n",
    "            model.build()\n",
    "            model.train(train[0], train[1], val[0], val[1], cfg.EPOCHS)\n",
    "            preds, labels = model.get_predictions_and_labels(test)\n",
    "            results = model.evaluate_predictions(preds, labels)\n",
    "            forgery_acc = self.compute_forgery_accuracy(model, extra)\n",
    "\n",
    "            preds_extra, labels_extra = model.get_predictions_and_labels(extra)\n",
    "            predictions_bin = model.strategy.evaluate_predictions(preds_extra, labels_extra)['predictions']\n",
    "            perc_fp = self.perc_false_positives(predictions_bin, labels_extra)\n",
    "            perc_fn = self.perc_false_negatives(predictions_bin, labels_extra)\n",
    "            perc_fp_list.append(perc_fp)\n",
    "            perc_fn_list.append(perc_fn)\n",
    "\n",
    "            test_accs.append(results['accuracy'])\n",
    "            forgery_accs.append(forgery_acc)\n",
    "            print(f\"[alpha={alpha}] Test Acc: {results['accuracy']:.3f}\\tForgery Acc: {forgery_acc:.3f}\\tFP%: {perc_fp:.2f}\\tFN%: {perc_fn:.2f}\")\n",
    "\n",
    "        # Plot accuracy\n",
    "        self.visualizer.plot_accuracy_vs_alpha(alpha_list, test_accs, forgery_accs)\n",
    "        # Plot FP/FN percentage\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(alpha_list, perc_fp_list, '-o', label='False Positive (%)', color='#6A5ACD')  \n",
    "        plt.plot(alpha_list, perc_fn_list, '-s', label='False Negative (%)', color='#228B22')  \n",
    "        plt.xlabel('FORGERIES_ALPHA')\n",
    "        plt.ylabel('Error Percentage (%)')\n",
    "        plt.title('False Positive and False Negative (%) vs FORGERIES_ALPHA')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:30:20.570418Z",
     "iopub.status.busy": "2025-07-06T17:30:20.570141Z",
     "iopub.status.idle": "2025-07-06T17:30:20.617904Z",
     "shell.execute_reply": "2025-07-06T17:30:20.617268Z",
     "shell.execute_reply.started": "2025-07-06T17:30:20.570392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg = Config(model_type=\"distance_euclidean\", N_SHOTS=9, FORGERIES_ALPHA=0.75, ENVIRONMENT=\"kaggle\")\n",
    "visualizer = Visualizer(cfg)\n",
    "controller = ExperimentController(cfg, SiameseModel, DatasetManager, visualizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:30:20.620931Z",
     "iopub.status.busy": "2025-07-06T17:30:20.620673Z",
     "iopub.status.idle": "2025-07-06T17:32:17.399002Z",
     "shell.execute_reply": "2025-07-06T17:32:17.398213Z",
     "shell.execute_reply.started": "2025-07-06T17:30:20.620912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "controller.single_experiment(blur_kernel_size=13, binarize=True, center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:32:17.400286Z",
     "iopub.status.busy": "2025-07-06T17:32:17.400081Z",
     "iopub.status.idle": "2025-07-06T17:32:17.403872Z",
     "shell.execute_reply": "2025-07-06T17:32:17.403253Z",
     "shell.execute_reply.started": "2025-07-06T17:32:17.400264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "controller.performance_analysis_forgeries_alpha([0, 0.1, 0.25, 0.5, 0.6, 0.75, 1.0], blur_kernel_size=13, binarize=True, center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T17:32:17.404981Z",
     "iopub.status.busy": "2025-07-06T17:32:17.404692Z",
     "iopub.status.idle": "2025-07-06T17:32:17.422351Z",
     "shell.execute_reply": "2025-07-06T17:32:17.421566Z",
     "shell.execute_reply.started": "2025-07-06T17:32:17.404966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "controller.performance_analysis_n_shots([1,2,3,4,5,6,7,8,9,10], blur_kernel_size=13, binarize=True, center=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1512017,
     "sourceId": 2497231,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
